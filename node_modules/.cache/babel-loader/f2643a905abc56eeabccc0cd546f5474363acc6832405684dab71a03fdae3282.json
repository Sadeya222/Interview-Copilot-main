{"ast":null,"code":"// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nexport var PropertyId;\n(function (PropertyId) {\n  /**\n   * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n   * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]].\n   * @member PropertyId.SpeechServiceConnection_Key\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n  /**\n   * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromEndpoint]].\n   * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n   * @member PropertyId.SpeechServiceConnection_Endpoint\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n  /**\n   * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n   * use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n   * @member PropertyId.SpeechServiceConnection_Region\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n  /**\n   * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n   * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n   * @member PropertyId.SpeechServiceAuthorization_Token\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n  /**\n   * The Cognitive Services Speech Service authorization type. Currently unused.\n   * @member PropertyId.SpeechServiceAuthorization_Type\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n  /**\n   * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.endpointId]].\n   * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n   * @member PropertyId.SpeechServiceConnection_EndpointId\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n  /**\n   * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n   * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n   * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n  /**\n   * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead, use [[SpeechTranslationConfig.voiceName]].\n   * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n   * @member PropertyId.SpeechServiceConnection_TranslationVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n  /**\n   * Translation features.\n   * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n  /**\n   * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[LanguageUnderstandingModel]].\n   * @member PropertyId.SpeechServiceConnection_IntentRegion\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n  /**\n   * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n  /**\n   * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n  /**\n   * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n  /**\n   * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n  /**\n   * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n   * This property is intended to be read-only. The SDK is using it internally.\n   * @member PropertyId.SpeechServiceConnection_RecoMode\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n  /**\n   * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n   * directly.\n   * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n   * @member PropertyId.SpeechServiceConnection_RecoLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n  /**\n   * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n   * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead use [[SessionEventArgs.sessionId]].\n   * @member PropertyId.Speech_SessionId\n   */\n  PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n  /**\n   * The spoken language to be synthesized (e.g. en-US)\n   * @member PropertyId.SpeechServiceConnection_SynthLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n  /**\n   * The name of the TTS voice to be used for speech synthesis\n   * @member PropertyId.SpeechServiceConnection_SynthVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n  /**\n   * The string to specify TTS output audio format\n   * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n  /**\n   * The list of comma separated languages used as possible source languages\n   * Added in version 1.13.0\n   * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n  /**\n   * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n   * to use this property directly.\n   * Instead use [[SpeechConfig.outputFormat]].\n   * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n   * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n  /**\n   * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n   * @member PropertyId.SpeechServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n  /**\n   * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n   * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n   * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n  /**\n   * The cancellation reason. Currently unused.\n   * @member PropertyId.CancellationDetails_Reason\n   */\n  PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n  /**\n   * The cancellation text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n  /**\n   * The Cancellation detailed text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonDetailedText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n  /**\n   * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n   * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n  /**\n   * The URL string built from speech configuration.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * NOTE: Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n  /**\n   * The initial silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n  /**\n   * The end silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n  /**\n   * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n   * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n   * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n   * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n   * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n   * behavior should be thoroughly validated as intended.\n   *\n   * For more information about timeout configuration that includes discussion of default behaviors, please visit\n   * https://aka.ms/csspeech/timeouts.\n   *\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n  /**\n   * A boolean value specifying whether audio logging is enabled in the service or not.\n   * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked\n   * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).\n   * The logs will be removed after 30 days.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 33] = \"SpeechServiceConnection_EnableAudioLogging\";\n  /**\n   * The speech service connection language identifier mode.\n   * Can be \"AtStart\" (the default), or \"Continuous\". See Language\n   * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\n   * for more details.\n   * Added in 1.25.0\n   **/\n  PropertyId[PropertyId[\"SpeechServiceConnection_LanguageIdMode\"] = 34] = \"SpeechServiceConnection_LanguageIdMode\";\n  /**\n   * A string value representing the desired endpoint version to target for Speech Recognition.\n   * Added in version 1.21.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 35] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n  /**\n  /**\n   * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).\n   * Added in version 1.23.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SpeakerIdMode\"] = 36] = \"SpeechServiceConnection_SpeakerIdMode\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity setting.\n   * Allowed values are \"masked\", \"removed\", and \"raw\".\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 37] = \"SpeechServiceResponse_ProfanityOption\";\n  /**\n   * A string value specifying which post processing option should be used by service.\n   * Allowed values are \"TrueText\".\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 38] = \"SpeechServiceResponse_PostProcessingOption\";\n  /**\n   * A boolean value specifying whether to include word-level timestamps in the response result.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 39] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n  /**\n   * The number of times a word has to be in partial results to be returned.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 40] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n  /**\n   * A string value specifying the output format option in the response result. Internal use only.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 41] = \"SpeechServiceResponse_OutputFormatOption\";\n  /**\n   * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 42] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n  /**\n   * A boolean value specifying whether to request WordBoundary events.\n   * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 43] = \"SpeechServiceResponse_RequestWordBoundary\";\n  /**\n   * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n   * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 44] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n  /**\n   * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n   * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 45] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n  /**\n   * Identifier used to connect to the backend service.\n   * @member PropertyId.Conversation_ApplicationId\n   */\n  PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 46] = \"Conversation_ApplicationId\";\n  /**\n   * Type of dialog backend to connect to.\n   * @member PropertyId.Conversation_DialogType\n   */\n  PropertyId[PropertyId[\"Conversation_DialogType\"] = 47] = \"Conversation_DialogType\";\n  /**\n   * Silence timeout for listening\n   * @member PropertyId.Conversation_Initial_Silence_Timeout\n   */\n  PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 48] = \"Conversation_Initial_Silence_Timeout\";\n  /**\n   * From Id to add to speech recognition activities.\n   * @member PropertyId.Conversation_From_Id\n   */\n  PropertyId[PropertyId[\"Conversation_From_Id\"] = 49] = \"Conversation_From_Id\";\n  /**\n   * ConversationId for the session.\n   * @member PropertyId.Conversation_Conversation_Id\n   */\n  PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 50] = \"Conversation_Conversation_Id\";\n  /**\n   * Comma separated list of custom voice deployment ids.\n   * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n   */\n  PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 51] = \"Conversation_Custom_Voice_Deployment_Ids\";\n  /**\n   * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n   * @member PropertyId.Conversation_Speech_Activity_Template\n   * Added in version 1.10.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 52] = \"Conversation_Speech_Activity_Template\";\n  /**\n   * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n   * @member PropertyId.Conversation_Request_Bot_Status_Messages\n   * Added in version 1.15.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 53] = \"Conversation_Request_Bot_Status_Messages\";\n  /**\n   * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n   * channel authentication.\n   * Added in version 1.15.1.\n   */\n  PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 54] = \"Conversation_Agent_Connection_Id\";\n  /**\n   * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromHost]].\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 55] = \"SpeechServiceConnection_Host\";\n  /**\n   * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 56] = \"ConversationTranslator_Host\";\n  /**\n   * Optionally set the the host's display name.\n   * Used when joining a conversation.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 57] = \"ConversationTranslator_Name\";\n  /**\n   * Optionally set a value for the X-CorrelationId request header.\n   * Used for troubleshooting errors in the server logs. It should be a valid guid.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 58] = \"ConversationTranslator_CorrelationId\";\n  /**\n   * Set the conversation token to be sent to the speech service. This enables the\n   * service to service call from the speech service to the Conversation Translator service for relaying\n   * recognitions. For internal use.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 59] = \"ConversationTranslator_Token\";\n  /**\n   * The reference text of the audio for pronunciation evaluation.\n   * For this and the following pronunciation assessment parameters, see\n   * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 60] = \"PronunciationAssessment_ReferenceText\";\n  /**\n   * The point system for pronunciation score calibration (FivePoint or HundredMark).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 61] = \"PronunciationAssessment_GradingSystem\";\n  /**\n   * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 62] = \"PronunciationAssessment_Granularity\";\n  /**\n   * Defines if enable miscue calculation.\n   * With this enabled, the pronounced words will be compared to the reference text,\n   * and will be marked with omission/insertion based on the comparison. The default setting is False.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 63] = \"PronunciationAssessment_EnableMiscue\";\n  /**\n   * The json string of pronunciation assessment parameters\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 64] = \"PronunciationAssessment_Json\";\n  /**\n   * Pronunciation assessment parameters.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 65] = \"PronunciationAssessment_Params\";\n  /**\n   * Version of Speaker Recognition API to use.\n   * Added in version 1.18.0\n   */\n  PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 66] = \"SpeakerRecognition_Api_Version\";\n  /**\n   * Specifies whether to allow load of data URL for web worker\n   * Allowed values are \"off\" and \"on\". Default is \"on\".\n   * Added in version 1.32.0\n   */\n  PropertyId[PropertyId[\"WebWorkerLoadType\"] = 67] = \"WebWorkerLoadType\";\n  /**\n   * Talking avatar service WebRTC session description protocol.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.33.0\n   */\n  PropertyId[PropertyId[\"TalkingAvatarService_WebRTC_SDP\"] = 68] = \"TalkingAvatarService_WebRTC_SDP\";\n})(PropertyId || (PropertyId = {}));","map":{"version":3,"names":["PropertyId"],"sources":["src/sdk/PropertyId.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\n/**\r\n * Defines speech property ids.\r\n * @class PropertyId\r\n */\r\nexport enum PropertyId {\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\r\n     * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]].\r\n     * @member PropertyId.SpeechServiceConnection_Key\r\n     */\r\n    SpeechServiceConnection_Key = 0,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromEndpoint]].\r\n     * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\r\n     * @member PropertyId.SpeechServiceConnection_Endpoint\r\n     */\r\n    SpeechServiceConnection_Endpoint,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\r\n     * use this property directly.\r\n     * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\r\n     * @member PropertyId.SpeechServiceConnection_Region\r\n     */\r\n    SpeechServiceConnection_Region,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\r\n     * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\r\n     * @member PropertyId.SpeechServiceAuthorization_Token\r\n     */\r\n    SpeechServiceAuthorization_Token,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service authorization type. Currently unused.\r\n     * @member PropertyId.SpeechServiceAuthorization_Type\r\n     */\r\n    SpeechServiceAuthorization_Type,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\r\n     * have to use this property directly.\r\n     * Instead, use [[SpeechConfig.endpointId]].\r\n     * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\r\n     * @member PropertyId.SpeechServiceConnection_EndpointId\r\n     */\r\n    SpeechServiceConnection_EndpointId,\r\n\r\n    /**\r\n     * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\r\n     * you shouldn't have to use this property directly.\r\n     * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\r\n     * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\r\n     * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\r\n     */\r\n    SpeechServiceConnection_TranslationToLanguages,\r\n\r\n    /**\r\n     * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead, use [[SpeechTranslationConfig.voiceName]].\r\n     * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationVoice\r\n     */\r\n    SpeechServiceConnection_TranslationVoice,\r\n\r\n    /**\r\n     * Translation features.\r\n     * @member PropertyId.SpeechServiceConnection_TranslationFeatures\r\n     */\r\n    SpeechServiceConnection_TranslationFeatures,\r\n\r\n    /**\r\n     * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[LanguageUnderstandingModel]].\r\n     * @member PropertyId.SpeechServiceConnection_IntentRegion\r\n     */\r\n    SpeechServiceConnection_IntentRegion,\r\n\r\n    /**\r\n     * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyHostName,\r\n\r\n    /**\r\n     * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPort,\r\n\r\n    /**\r\n     * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyUserName,\r\n\r\n    /**\r\n     * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\r\n     * You shouldn't have to use this property directly.\r\n     * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\r\n     * Added in version 1.4.0.\r\n     */\r\n    SpeechServiceConnection_ProxyPassword,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * @member PropertyId.SpeechServiceConnection_RecoMode\r\n     */\r\n    SpeechServiceConnection_RecoMode,\r\n\r\n    /**\r\n     * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\r\n     * directly.\r\n     * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\r\n     * @member PropertyId.SpeechServiceConnection_RecoLanguage\r\n     */\r\n    SpeechServiceConnection_RecoLanguage,\r\n\r\n    /**\r\n     * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\r\n     * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\r\n     * property directly.\r\n     * Instead use [[SessionEventArgs.sessionId]].\r\n     * @member PropertyId.Speech_SessionId\r\n     */\r\n    Speech_SessionId,\r\n\r\n    /**\r\n     * The spoken language to be synthesized (e.g. en-US)\r\n     * @member PropertyId.SpeechServiceConnection_SynthLanguage\r\n     */\r\n    SpeechServiceConnection_SynthLanguage,\r\n\r\n    /**\r\n     * The name of the TTS voice to be used for speech synthesis\r\n     * @member PropertyId.SpeechServiceConnection_SynthVoice\r\n     */\r\n    SpeechServiceConnection_SynthVoice,\r\n\r\n    /**\r\n     * The string to specify TTS output audio format\r\n     * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\r\n     */\r\n    SpeechServiceConnection_SynthOutputFormat,\r\n\r\n    /**\r\n     * The list of comma separated languages used as possible source languages\r\n     * Added in version 1.13.0\r\n     * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\r\n     */\r\n    SpeechServiceConnection_AutoDetectSourceLanguages,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\r\n     * to use this property directly.\r\n     * Instead use [[SpeechConfig.outputFormat]].\r\n     * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestDetailedResultTrueFalse,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\r\n     * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\r\n     */\r\n    SpeechServiceResponse_RequestProfanityFilterTrueFalse,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\r\n     * @member PropertyId.SpeechServiceResponse_JsonResult\r\n     */\r\n    SpeechServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\r\n     * use this property directly. Instead use [[CancellationDetails.errorDetails]].\r\n     * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\r\n     */\r\n    SpeechServiceResponse_JsonErrorDetails,\r\n\r\n    /**\r\n     * The cancellation reason. Currently unused.\r\n     * @member PropertyId.CancellationDetails_Reason\r\n     */\r\n    CancellationDetails_Reason,\r\n\r\n    /**\r\n     * The cancellation text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonText\r\n     */\r\n    CancellationDetails_ReasonText,\r\n\r\n    /**\r\n     * The Cancellation detailed text. Currently unused.\r\n     * @member PropertyId.CancellationDetails_ReasonDetailedText\r\n     */\r\n    CancellationDetails_ReasonDetailedText,\r\n\r\n    /**\r\n     * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\r\n     * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\r\n     */\r\n    LanguageUnderstandingServiceResponse_JsonResult,\r\n\r\n    /**\r\n     * The URL string built from speech configuration.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * NOTE: Added in version 1.7.0.\r\n     */\r\n    SpeechServiceConnection_Url,\r\n\r\n    /**\r\n     * The initial silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_InitialSilenceTimeoutMs,\r\n\r\n    /**\r\n     * The end silence timeout value (in milliseconds) used by the service.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EndSilenceTimeoutMs,\r\n\r\n    /**\r\n     * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\r\n     * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\r\n     * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\r\n     * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\r\n     * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\r\n     * behavior should be thoroughly validated as intended.\r\n     *\r\n     * For more information about timeout configuration that includes discussion of default behaviors, please visit\r\n     * https://aka.ms/csspeech/timeouts.\r\n     *\r\n     * Added in version 1.21.0.\r\n     */\r\n    Speech_SegmentationSilenceTimeoutMs,\r\n\r\n    /**\r\n     * A boolean value specifying whether audio logging is enabled in the service or not.\r\n     * Audio and content logs are stored either in Microsoft-owned storage, or in your own storage account linked\r\n     * to your Cognitive Services subscription (Bring Your Own Storage (BYOS) enabled Speech resource).\r\n     * The logs will be removed after 30 days.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceConnection_EnableAudioLogging,\r\n\r\n    /**\r\n     * The speech service connection language identifier mode.\r\n     * Can be \"AtStart\" (the default), or \"Continuous\". See Language\r\n     * Identification document https://aka.ms/speech/lid?pivots=programming-language-javascript\r\n     * for more details.\r\n     * Added in 1.25.0\r\n     **/\r\n    SpeechServiceConnection_LanguageIdMode,\r\n\r\n    /**\r\n     * A string value representing the desired endpoint version to target for Speech Recognition.\r\n     * Added in version 1.21.0\r\n     */\r\n    SpeechServiceConnection_RecognitionEndpointVersion,\r\n\r\n    /**\r\n    /**\r\n     * A string value the current speaker recognition scenario/mode (TextIndependentIdentification, etc.).\r\n     * Added in version 1.23.0\r\n     */\r\n    SpeechServiceConnection_SpeakerIdMode,\r\n\r\n    /**\r\n     * The requested Cognitive Services Speech Service response output profanity setting.\r\n     * Allowed values are \"masked\", \"removed\", and \"raw\".\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_ProfanityOption,\r\n\r\n    /**\r\n     * A string value specifying which post processing option should be used by service.\r\n     * Allowed values are \"TrueText\".\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_PostProcessingOption,\r\n\r\n    /**\r\n     * A boolean value specifying whether to include word-level timestamps in the response result.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_RequestWordLevelTimestamps,\r\n\r\n    /**\r\n     * The number of times a word has to be in partial results to be returned.\r\n     * Added in version 1.7.0\r\n     */\r\n    SpeechServiceResponse_StablePartialResultThreshold,\r\n\r\n    /**\r\n     * A string value specifying the output format option in the response result. Internal use only.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_OutputFormatOption,\r\n\r\n    /**\r\n     * A boolean value to request for stabilizing translation partial results by omitting words in the end.\r\n     * Added in version 1.7.0.\r\n     */\r\n    SpeechServiceResponse_TranslationRequestStablePartialResult,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request WordBoundary events.\r\n     * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestWordBoundary,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\r\n     * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestPunctuationBoundary,\r\n\r\n    /**\r\n     * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\r\n     * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\r\n     * Added in version 1.21.0.\r\n     */\r\n    SpeechServiceResponse_RequestSentenceBoundary,\r\n\r\n    /**\r\n     * Identifier used to connect to the backend service.\r\n     * @member PropertyId.Conversation_ApplicationId\r\n     */\r\n    Conversation_ApplicationId,\r\n\r\n    /**\r\n     * Type of dialog backend to connect to.\r\n     * @member PropertyId.Conversation_DialogType\r\n     */\r\n    Conversation_DialogType,\r\n\r\n    /**\r\n     * Silence timeout for listening\r\n     * @member PropertyId.Conversation_Initial_Silence_Timeout\r\n     */\r\n    Conversation_Initial_Silence_Timeout,\r\n\r\n    /**\r\n     * From Id to add to speech recognition activities.\r\n     * @member PropertyId.Conversation_From_Id\r\n     */\r\n    Conversation_From_Id,\r\n\r\n    /**\r\n     * ConversationId for the session.\r\n     * @member PropertyId.Conversation_Conversation_Id\r\n     */\r\n    Conversation_Conversation_Id,\r\n\r\n    /**\r\n     * Comma separated list of custom voice deployment ids.\r\n     * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\r\n     */\r\n    Conversation_Custom_Voice_Deployment_Ids,\r\n\r\n    /**\r\n     * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\r\n     * @member PropertyId.Conversation_Speech_Activity_Template\r\n     * Added in version 1.10.0.\r\n     */\r\n    Conversation_Speech_Activity_Template,\r\n\r\n    /**\r\n     * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\r\n     * @member PropertyId.Conversation_Request_Bot_Status_Messages\r\n     * Added in version 1.15.0.\r\n     */\r\n    Conversation_Request_Bot_Status_Messages,\r\n\r\n    /**\r\n     * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\r\n     * channel authentication.\r\n     * Added in version 1.15.1.\r\n     */\r\n    Conversation_Agent_Connection_Id,\r\n\r\n    /**\r\n     * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Instead, use [[SpeechConfig.fromHost]].\r\n     */\r\n    SpeechServiceConnection_Host,\r\n\r\n    /**\r\n     * Set the host for service calls to the Conversation Translator REST management and websocket calls.\r\n     */\r\n    ConversationTranslator_Host,\r\n\r\n    /**\r\n     * Optionally set the the host's display name.\r\n     * Used when joining a conversation.\r\n     */\r\n    ConversationTranslator_Name,\r\n\r\n    /**\r\n     * Optionally set a value for the X-CorrelationId request header.\r\n     * Used for troubleshooting errors in the server logs. It should be a valid guid.\r\n     */\r\n    ConversationTranslator_CorrelationId,\r\n\r\n    /**\r\n     * Set the conversation token to be sent to the speech service. This enables the\r\n     * service to service call from the speech service to the Conversation Translator service for relaying\r\n     * recognitions. For internal use.\r\n     */\r\n    ConversationTranslator_Token,\r\n\r\n    /**\r\n     * The reference text of the audio for pronunciation evaluation.\r\n     * For this and the following pronunciation assessment parameters, see\r\n     * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_ReferenceText,\r\n\r\n    /**\r\n     * The point system for pronunciation score calibration (FivePoint or HundredMark).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_GradingSystem,\r\n\r\n    /**\r\n     * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Granularity,\r\n\r\n    /**\r\n     * Defines if enable miscue calculation.\r\n     * With this enabled, the pronounced words will be compared to the reference text,\r\n     * and will be marked with omission/insertion based on the comparison. The default setting is False.\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_EnableMiscue,\r\n\r\n    /**\r\n     * The json string of pronunciation assessment parameters\r\n     * Under normal circumstances, you shouldn't have to use this property directly.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Json,\r\n\r\n    /**\r\n     * Pronunciation assessment parameters.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * Added in version 1.15.0\r\n     */\r\n    PronunciationAssessment_Params,\r\n\r\n    /**\r\n     * Version of Speaker Recognition API to use.\r\n     * Added in version 1.18.0\r\n     */\r\n    SpeakerRecognition_Api_Version,\r\n\r\n    /**\r\n     * Specifies whether to allow load of data URL for web worker\r\n     * Allowed values are \"off\" and \"on\". Default is \"on\".\r\n     * Added in version 1.32.0\r\n     */\r\n    WebWorkerLoadType,\r\n\r\n    /**\r\n     * Talking avatar service WebRTC session description protocol.\r\n     * This property is intended to be read-only. The SDK is using it internally.\r\n     * Added in version 1.33.0\r\n     */\r\n    TalkingAvatarService_WebRTC_SDP,\r\n}\r\n"],"mappings":"AAAA;AACA;AAEA;;;;AAIA,WAAYA,UA2eX;AA3eD,WAAYA,UAAU;EAElB;;;;;;;EAOAA,UAAA,CAAAA,UAAA,oEAA+B;EAE/B;;;;;;;EAOAA,UAAA,CAAAA,UAAA,8EAAgC;EAEhC;;;;;;EAMAA,UAAA,CAAAA,UAAA,0EAA8B;EAE9B;;;;;;;EAOAA,UAAA,CAAAA,UAAA,8EAAgC;EAEhC;;;;EAIAA,UAAA,CAAAA,UAAA,4EAA+B;EAE/B;;;;;;;EAOAA,UAAA,CAAAA,UAAA,kFAAkC;EAElC;;;;;;;EAOAA,UAAA,CAAAA,UAAA,0GAA8C;EAE9C;;;;;;;EAOAA,UAAA,CAAAA,UAAA,8FAAwC;EAExC;;;;EAIAA,UAAA,CAAAA,UAAA,oGAA2C;EAE3C;;;;;EAKAA,UAAA,CAAAA,UAAA,sFAAoC;EAEpC;;;;;;EAMAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;;EAMAA,UAAA,CAAAA,UAAA,iFAAiC;EAEjC;;;;;;EAMAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;;EAMAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,+EAAgC;EAEhC;;;;;;EAMAA,UAAA,CAAAA,UAAA,uFAAoC;EAEpC;;;;;;;EAOAA,UAAA,CAAAA,UAAA,+CAAgB;EAEhB;;;;EAIAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;EAIAA,UAAA,CAAAA,UAAA,mFAAkC;EAElC;;;;EAIAA,UAAA,CAAAA,UAAA,iGAAyC;EAEzC;;;;;EAKAA,UAAA,CAAAA,UAAA,iHAAiD;EAEjD;;;;;;EAMAA,UAAA,CAAAA,UAAA,uHAAoD;EAEpD;;;;EAIAA,UAAA,CAAAA,UAAA,yHAAqD;EAErD;;;;EAIAA,UAAA,CAAAA,UAAA,+EAAgC;EAEhC;;;;;EAKAA,UAAA,CAAAA,UAAA,2FAAsC;EAEtC;;;;EAIAA,UAAA,CAAAA,UAAA,mEAA0B;EAE1B;;;;EAIAA,UAAA,CAAAA,UAAA,2EAA8B;EAE9B;;;;EAIAA,UAAA,CAAAA,UAAA,2FAAsC;EAEtC;;;;EAIAA,UAAA,CAAAA,UAAA,6GAA+C;EAE/C;;;;;EAKAA,UAAA,CAAAA,UAAA,qEAA2B;EAE3B;;;;EAIAA,UAAA,CAAAA,UAAA,6GAA+C;EAE/C;;;;EAIAA,UAAA,CAAAA,UAAA,qGAA2C;EAE3C;;;;;;;;;;;;;EAaAA,UAAA,CAAAA,UAAA,qFAAmC;EAEnC;;;;;;;EAOAA,UAAA,CAAAA,UAAA,mGAA0C;EAE1C;;;;;;;EAOAA,UAAA,CAAAA,UAAA,2FAAsC;EAEtC;;;;EAIAA,UAAA,CAAAA,UAAA,mHAAkD;EAElD;;;;;EAKAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,mGAA0C;EAE1C;;;;EAIAA,UAAA,CAAAA,UAAA,+GAAgD;EAEhD;;;;EAIAA,UAAA,CAAAA,UAAA,mHAAkD;EAElD;;;;EAIAA,UAAA,CAAAA,UAAA,+FAAwC;EAExC;;;;EAIAA,UAAA,CAAAA,UAAA,qIAA2D;EAE3D;;;;;EAKAA,UAAA,CAAAA,UAAA,iGAAyC;EAEzC;;;;;EAKAA,UAAA,CAAAA,UAAA,+GAAgD;EAEhD;;;;;EAKAA,UAAA,CAAAA,UAAA,yGAA6C;EAE7C;;;;EAIAA,UAAA,CAAAA,UAAA,mEAA0B;EAE1B;;;;EAIAA,UAAA,CAAAA,UAAA,6DAAuB;EAEvB;;;;EAIAA,UAAA,CAAAA,UAAA,uFAAoC;EAEpC;;;;EAIAA,UAAA,CAAAA,UAAA,uDAAoB;EAEpB;;;;EAIAA,UAAA,CAAAA,UAAA,uEAA4B;EAE5B;;;;EAIAA,UAAA,CAAAA,UAAA,+FAAwC;EAExC;;;;;EAKAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,+FAAwC;EAExC;;;;;EAKAA,UAAA,CAAAA,UAAA,+EAAgC;EAEhC;;;;EAIAA,UAAA,CAAAA,UAAA,uEAA4B;EAE5B;;;EAGAA,UAAA,CAAAA,UAAA,qEAA2B;EAE3B;;;;EAIAA,UAAA,CAAAA,UAAA,qEAA2B;EAE3B;;;;EAIAA,UAAA,CAAAA,UAAA,uFAAoC;EAEpC;;;;;EAKAA,UAAA,CAAAA,UAAA,uEAA4B;EAE5B;;;;;;;EAOAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,yFAAqC;EAErC;;;;;EAKAA,UAAA,CAAAA,UAAA,qFAAmC;EAEnC;;;;;;;EAOAA,UAAA,CAAAA,UAAA,uFAAoC;EAEpC;;;;;EAKAA,UAAA,CAAAA,UAAA,uEAA4B;EAE5B;;;;;EAKAA,UAAA,CAAAA,UAAA,2EAA8B;EAE9B;;;;EAIAA,UAAA,CAAAA,UAAA,2EAA8B;EAE9B;;;;;EAKAA,UAAA,CAAAA,UAAA,iDAAiB;EAEjB;;;;;EAKAA,UAAA,CAAAA,UAAA,6EAA+B;AACnC,CAAC,EA3eWA,UAAU,KAAVA,UAAU"},"metadata":{},"sourceType":"module","externalDependencies":[]}